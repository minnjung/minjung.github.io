---
layout: default
---

Hello!
I am a Ph.D student in CSE at Seoul National University, and studying under the supervision of [Prof. Gunhee Kim](https://vision.snu.ac.kr/gunhee/).

My research interests are in the field of 3D Place Recognition and Visual Localization, especially about
(i) understanding the scene from images and point clouds,
(ii) dealing with multi-modalities,
and (iii) utilizing high-level semantic information for place recognition.


### Education


<h4 class="education">
  <i class="material-icons md-18">account_balance</i>
  <a href="http://en.snu.ac.kr/">Seoul National University (SNU)</a>, Seoul, Korea
  <sup>2018.03 - Current</sup>
</h4>

- Integrated M.S./Ph.D. student in [Computer Science and Engineering]
- Advisor: [Prof. Gunhee Kim](https://vision.snu.ac.kr/gunhee/)

[Computer Science and Engineering]: https://cse.snu.ac.kr/en

<h4 class="education">
  <i class="material-icons md-18">school</i>
  <a href="http://en.snu.ac.kr/">Sogang University</a>, Seoul, Korea
  <sup>2014.03 - 2018.02</sup>
</h4>

- B.S. in [Computer Science and Engineering]
- Cumulative GPA: 3.58 / 4.3 (3.88 / 4.5), Magna Cum Laude

[Computer Science and Engineering]: https://ecs.sogang.ac.kr/ecs/index_new.html


### Publications

<!--
- [Shared Neural Representation-inspired Empathetic Response Generation]() <br/>
Hyunwoo Kim, **Byeongchang Kim** and Gunhee Kim <br/>
ICLR 2021 Brain2AI Workshop
-->

- [How Robust are Fact Checking Systems on Colloquial Claims?]() <br/>
**Byeongchang Kim**\*, Hyunwoo Kim\*, Seokhee Hong and Gunhee Kim <br/>
NAACL-HLT 2021
<small>(also at ICLR 2021 [Neural Conversational AI (NeuCAIR) Workshop](https://sites.google.com/view/neucair-workshop))</small> <br/>


- [*Will I Sound Like Me*? Improving Persona Consistency in Dialogues through <br/> Pragmatic Self-Consciousness](https://arxiv.org/abs/2004.05816) <br/>
Hyunwoo Kim, **Byeongchang Kim** and Gunhee Kim <br/>
EMNLP 2020
<small>(also at ICLR 2020 [Bridging AI and Cognitive Science (BAICS) Workshop](https://baicsworkshop.github.io/papers.html) (oral))</small> <br/>
<a class="code" href="https://github.com/skywalker023/pragmatic-consistency">[code]</a>


- [Sequential Latent Knowledge Selection for Knowledge-Grounded Dialogue](https://arxiv.org/abs/2002.07510) <br/>
**Byeongchang Kim**, Jaewoo Ahn and Gunhee Kim <br/>
ICLR 2020 (spotlight) <br/>
<a class="code" href="https://openreview.net/forum?id=Hke0K1HKwr">[OpenReview]</a>
<a class="code" href="https://github.com/bckim92/sequential-knowledge-transformer">[code/dataset]</a>
<a class="code" href="https://drive.google.com/open?id=16tdavuCPoWwtGqg9KAkqI71TxG8nVkbs">[slide]</a>

- [*AudioCaps*: Generating Captions for Audios in The Wild](https://www.aclweb.org/anthology/N19-1011/)<br/>
Chris Dongjoo Kim, **Byeongchang Kim**, Hyunmin Lee and Gunhee Kim <br/>
NAACL-HLT 2019 (oral) <br/>
<a class="code" href="https://audiocaps.github.io/">Project Page [code/dataset]</a>

- [Abstractive Summarization of *Reddit* Posts with Multi-level Memory Networks](https://arxiv.org/abs/1811.00783) <br/>
**Byeongchang Kim**, Hyunwoo Kim and Gunhee Kim <br/>
NAACL-HLT 2019 (oral) <br/>
<a class="code" href="https://github.com/ctr4si/MMN/">[code/dataset]</a>
<a class="code" href="https://drive.google.com/open?id=17nGtwNewII9Uqxmq4Rp_xmQtCJPAZRnz">[slide]</a>

- [Towards Personalized Image Captioning via Multimodal Memory Networks](https://ieeexplore.ieee.org/abstract/document/8334621/) <br/>
Cesc Chunseong Park, **Byeongchang Kim** and Gunhee Kim <br/>
IEEE TPAMI 2018 <br/>
<a class="code" href="https://github.com/cesc-park/attend2u">[code/dataset]</a>
<a class="code" href="https://drive.google.com/open?id=1U15fsIXTqBgrKH7WcD9Vgru_A0OPBsFq">[slide]</a>

- [*Attend to you*: Personalized Image Captioning with Context Sequence Memory Networks](https://arxiv.org/abs/1704.06485) <br/>
Cesc Chunseong Park, **Byeongchang Kim** and Gunhee Kim <br/>
CVPR 2017 (spotlight) <br/>
<a class="code" href="https://github.com/cesc-park/attend2u">[code/dataset]</a>
<a class="code" href="https://drive.google.com/open?id=1Om5_2Q4YpU1kzOdE62Fnb7SfLwhcWiZS">[slide]</a>
<a class="code" href="https://drive.google.com/open?id=1ZtFnQLTx6b6npKhJgbn1yGxK0-SjdCjp">[poster]</a>


### Awards & Honorships

- NAVER PhD Fellowship (2020)
- [Qualcomm Innovation Fellowship Korea](https://www.qualcomm.com/research/research/university-relations/innovation-fellowship/2020-south-korea) (2020)
- [Samsung Humantech Paper Award](https://humantech.samsung.com/saitext/index.jsp) (Gold Prize, 1st in Signal Processing, 2020)
- [Google PhD Fellowship](https://ai.googleblog.com/2019/09/announcement-of-2019-fellowship.html) (Natural Language Processing, 2019)
- [Google Conference and Travel Scholarships](https://buildyourfuture.withgoogle.com/scholarships/google-travel-scholarships/) (2019)
- [Samsung Convergence Software Course](https://cse.snu.ac.kr/scsc/node/19) Mentor Scholarship (2016-2017)

### Development Projects

- [language-evaluation]
<a href="https://github.com/bckim92/language-evaluation">
  <img class="shield-star" src="https://img.shields.io/github/stars/bckim92/language-evaluation.svg?style=social&amp;label=Star&amp;maxAge=86400">
</a><br/>
ðŸ“‹ Collection of evaluation code for natural language generation.

- [zsh-autoswitch-conda]
<a href="https://github.com/bckim92/language-evaluation">
  <img class="shield-star" src="https://img.shields.io/github/stars/bckim92/zsh-autoswitch-conda.svg?style=social&amp;label=Star&amp;maxAge=86400">
</a><br/>
ðŸ’» ZSH plugin to automatically switch conda environments as you move between directories

<!--
- [dash-docset-allennlp]
<a href="https://github.com/bckim92/dash-docset-allennlp">
  <img class="shield-star" src="https://img.shields.io/github/stars/bckim92/dash-docset-allennlp.svg?style=social&amp;label=Star&amp;maxAge=86400">
</a><br/>
ðŸ“„ Dash docset for AllenNLP
-->
- SNUVL GPU Cluster<br/>
I am one of the main system administrators of SNUVL GPU cluster, which effectively serves ~200 GPUs to ~35 users.
We use Ansible, LDAP, Slurm, Prometheus, Grafana, DFS, gpustat-web, and IPMI to build a scalable and stable system.

[language-evaluation]: https://github.com/bckim92/language-evaluation
[zsh-autoswitch-conda]: https://github.com/bckim92/zsh-autoswitch-conda
[dash-docset-allennlp]: https://github.com/bckim92/dash-docset-allennlp
